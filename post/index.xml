<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | Archit Parnami</title>
    <link>http://localhost:1313/post/</link>
      <atom:link href="http://localhost:1313/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>@2024 Archit Parnami. All Rights Reserved.</copyright><lastBuildDate>Mon, 03 Aug 2020 16:39:18 -0400</lastBuildDate>
    <image>
      <url>http://localhost:1313/images/icon_hu_e747e089a9e68c83.png</url>
      <title>Posts</title>
      <link>http://localhost:1313/post/</link>
    </image>
    
    <item>
      <title>Laplacian Regularized Few-Shot Learning</title>
      <link>http://localhost:1313/post/laplacian-fsl/</link>
      <pubDate>Mon, 03 Aug 2020 16:39:18 -0400</pubDate>
      <guid>http://localhost:1313/post/laplacian-fsl/</guid>
      <description>&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Paper&lt;/th&gt;
          &lt;th&gt;
&lt;a href=&#34;https://arxiv.org/abs/2006.15486&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/2006.15486&lt;/a&gt;&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;Code&lt;/td&gt;
          &lt;td&gt;
&lt;a href=&#34;https://github.com/imtiazziko/LaplacianShot&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/imtiazziko/LaplacianShot&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h1 id=&#34;main-idea&#34;&gt;Main Idea&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Transfer Learning:&lt;/strong&gt; Image embeddings are obtained by pre-training a network on the set of base classes using cross-entropy loss.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Transductive Inference:&lt;/strong&gt; Jointly classify all the query examples together.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;methodology&#34;&gt;Methodology&lt;/h1&gt;
&lt;p&gt;Given a labeled support set $\mathbb{X_s} = \bigcup_{c=1}^C$ with C &lt;em&gt;test&lt;/em&gt; classes, where each novel class $c$ has $|\mathbb{X_s^c}|$ labeled examples. Ex., $|\mathbb{X_s^c}| = 1$ for one-shot learning. The object is then to classify unlabeled unseen query sample set $|\mathbb{X_q}|$.&lt;/p&gt;
&lt;p&gt;Let $f_{\theta}$ be the embedding function with parameters $\theta$. Then:&lt;/p&gt;
&lt;p&gt;$$x_q = f_{\theta}(z_q) \in \mathbb{R}^M,$$
where $x_q$ is the encoding of the data point $z_q$.&lt;/p&gt;
&lt;p&gt;For each query point $x_q$, let there be a assignment vector $\mathbf{y_q} = [y_{q,1}, &amp;hellip;, y_{q,C}]^t \in {0,1}^C$&lt;/p&gt;
&lt;p&gt;so that binary $y_{q,c}$ is equal to 1 if $x_q$ belongs to class $c$. Then $\mathbf{Y}$ denotes the $N \times C$ matrix whose rows are formed by $\mathbf{y}_q$, where $N$ is the number of query points  in $\mathbb{X_q}$. Then the objective to minimize at inference is given by (to find a $\mathbf{Y}$ such that):&lt;/p&gt;
&lt;p&gt;$$\mathcal{E}(\mathbf{Y}) = \mathcal{N}(\mathbf{Y}) + \frac{\lambda}{2} \mathcal{L}(\mathbf{Y})$$&lt;/p&gt;
&lt;p&gt;where&lt;/p&gt;
&lt;p&gt;$$\mathcal{N}(\mathbf{Y}) = \sum_{q=1}^N \sum_{c=1}^C y_{q,c}  d(x_q - \mathbf{m}_c)$$&lt;/p&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;p&gt;$$\mathcal{L}(\mathbf{Y}) = \frac{1}{2} \sum_{q,p} w(x_q, x_p) || \mathbf{y}_q - \mathbf{y}_p||^2$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\mathcal{N}(\mathbf{Y})$ is minimized globally when each query point is assigned to the class of the nearest prototype $\mathbf{m}_c$ from the support set using a distance metric $d(x_q, m_c)$.&lt;/li&gt;
&lt;li&gt;The Laplacian term (regularizer), $\mathcal{L}(\mathbf{Y})$, encourages nearby points $(x_p, x_q)$ in the label space to the same latent label assignment. $w$ is any similarity metric.&lt;/li&gt;
&lt;li&gt;$\lambda$ is regularization parameter whose value is found by measuring performance on validation set.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Using an iterative bound optimization procedure (Ex., Expectation-Maximization (EM)), $\mathcal{E}(\mathbf{Y})$  is minimized and $\mathbf{Y}$ is found. Their optimization procedure converges within 15 iterations. Please refer to the paper for details on optimization method.&lt;/p&gt;
&lt;h1 id=&#34;results&#34;&gt;Results&lt;/h1&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Network&lt;/th&gt;
          &lt;th&gt;dataset&lt;/th&gt;
          &lt;th&gt;1-shot&lt;/th&gt;
          &lt;th&gt;5-shot&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;ResNet-18&lt;/td&gt;
          &lt;td&gt;&lt;em&gt;mini&lt;/em&gt;ImageNet&lt;/td&gt;
          &lt;td&gt;$72.11 \pm 0.19$&lt;/td&gt;
          &lt;td&gt;$82.31 \pm 0.14$&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;ResNet-18&lt;/td&gt;
          &lt;td&gt;&lt;em&gt;tiered&lt;/em&gt;ImageNet&lt;/td&gt;
          &lt;td&gt;$78.98 \pm 0.21$&lt;/td&gt;
          &lt;td&gt;$86.39 \pm 0.16$&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;ResNet-18&lt;/td&gt;
          &lt;td&gt;CUB&lt;/td&gt;
          &lt;td&gt;$80.96$&lt;/td&gt;
          &lt;td&gt;$88.68$&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;ResNet-18&lt;/td&gt;
          &lt;td&gt;&lt;em&gt;mini&lt;/em&gt;ImageNet $\rightarrow$ CUB&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
          &lt;td&gt;$55.46$&lt;/td&gt;
          &lt;td&gt;$66.33$&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/post/laplacian-fsl/Laplace-FSL-1.png&#34; alt=&#34;Finding the right $\lambda$&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/post/laplacian-fsl/Laplace-FSL-2.png&#34; alt=&#34;Convergence of optimization procedure&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;cite--bibtex&#34;&gt;Cite / BibTex&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;@article{Ziko2020LaplacianRF,
  title={Laplacian Regularized Few-Shot Learning},
  author={Imtiaz Masud Ziko and Jose Dolz and {\&#39;E}ric Granger and Ismail Ben Ayed},
  journal={ArXiv},
  year={2020},
  volume={abs/2006.15486}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;Cross Domain FSL: Training on miniImageNet and testing on CUB.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
