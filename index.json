[{"authors":["Archit Parnami"],"categories":null,"content":"Machine Learning Scientist with 4 years of experience developing scalable models for the banking sector, alongside 5 years of research and 3 years in software engineering. Technical expertise spans machine learning and system integration. Strong communicator and a leader, with a focus on delivering solutions that align with business goals and driving impactful projects through cross-functional teamwork.\n","date":1652817600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1652817600,"objectID":"c1cb694bb8181e1f92c7bba78ce2f7e9","permalink":"https://ArchitParnami.github.io/author/","publishdate":"2022-05-17T16:00:00-04:00","relpermalink":"/author/","section":"authors","summary":"Machine Learning Scientist with 4 years of experience developing scalable models for the banking sector, alongside 5 years of research and 3 years in software engineering. Technical expertise spans machine learning and system integration. Strong communicator and a leader, with a focus on delivering solutions that align with business goals and driving impactful projects through cross-functional teamwork.\n","tags":null,"title":"","type":"authors"},{"authors":["","Muhammad Usama","Liyue Fan","Minwoo Lee"],"categories":["Few-Shot Learning"],"content":"","date":1652817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1652817600,"objectID":"25d0fb892a6e9d9d9f63d33f5a52adf9","permalink":"https://ArchitParnami.github.io/publication/05-fs-privacy/","publishdate":"2022-05-17T16:00:00-04:00","relpermalink":"/publication/05-fs-privacy/","section":"publication","summary":"Accepted in IEEE WCCI International Joint Conference on Neural Networks (IJCNN), July 2022, Padua, Italy","tags":["Few-Shot Learning","Privacy","Cloud","Image Classification","Differential Privacy","Meta-Learning"],"title":"Privacy Enhancement for Cloud-Based Few-Shot Learning","type":"publication"},{"authors":["","Minwoo Lee"],"categories":["Few-Shot Learning"],"content":"","date":1646686729,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646686729,"objectID":"91af78d147e7eb1c7cbfe39cd87531cc","permalink":"https://ArchitParnami.github.io/publication/03-fsl-survey/","publishdate":"2022-03-07T16:00:00-04:00","relpermalink":"/publication/03-fsl-survey/","section":"publication","summary":"Few-Shot Learning refers to the problem of learning the underlying pattern in the data just from a few training samples. Requiring a large number of data samples, many deep learning solutions suffer from data hunger and extensively high computation time and resources. Furthermore, data is often not available due to not only the nature of the problem or privacy concerns but also the cost of data preparation. Data collection, preprocessing, and labeling are strenuous human tasks. Therefore, few-shot learning that could drastically reduce the turnaround time of building machine learning applications emerges as a low-cost solution. This survey paper comprises a representative list of recently proposed few-shot learning algorithms. Given the learning dynamics and characteristics, the approaches to few-shot learning problems are discussed in the perspectives of meta-learning, transfer learning, and hybrid approaches (i.e., different variations of the few-shot learning problem). ","tags":["Few-Shot Learning","Meta-Learning","Survey"],"title":"Learning from Few Examples: A Summary of Approaches to Few-Shot Learning","type":"publication"},{"authors":["","Rahul Singh","Tarun Joshi"],"categories":["NLP"],"content":"","date":1637182729,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1637182729,"objectID":"7a159f15cb43077ca38db8bfb7aec382","permalink":"https://ArchitParnami.github.io/publication/02-pruning/","publishdate":"2022-03-20T16:00:00-04:00","relpermalink":"/publication/02-pruning/","section":"publication","summary":"Recent years have seen a growing adoption of Transformer models such as BERT in Natural Language Processing and even in Computer Vision. However, due to their size, there has been limited adoption of such models within resource-constrained computing environments. This paper proposes novel pruning algorithm to compress transformer models by eliminating redundant Attention Heads. We apply the A* search algorithm to obtain a pruned model with strict accuracy guarantees. Our results indicate that the method could eliminate as much as 40% of the attention heads in the BERT transformer model with no loss in accuracy. ","tags":["Model Compression","Sentiment Analysis","Transformers"],"title":"Pruning Attention Heads of Transformer Models Using A* Search","type":"publication"},{"authors":["","Mayuri Deshpande","Minwoo Lee"],"categories":["Graph"],"content":"","date":1637179200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1637179200,"objectID":"7e3b0efa8aa222f8d994fd40a92e1555","permalink":"https://ArchitParnami.github.io/publication/04-graph/","publishdate":"2021-11-17T16:00:00-04:00","relpermalink":"/publication/04-graph/","section":"publication","summary":"Accepted in ESWC 3rd International Workshop on Knowledge Graph Construction (KGCW), May 2022, Crete, Greece","tags":["Link Prediction","Social Networks","Graph Embedding"],"title":"Transformation of Node to Knowledge Graph Embeddings for Faster Link Prediction in Social Networks","type":"publication"},{"authors":["admin"],"categories":["Paper Implementation"],"content":"","date":1596489192,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596489192,"objectID":"4aaf76d3d96cdd3a726474acd457372b","permalink":"https://ArchitParnami.github.io/project/dp-pix/","publishdate":"2020-08-03T17:13:12-04:00","relpermalink":"/project/dp-pix/","section":"project","summary":"","tags":["Differential Privacy","Image Pixelation"],"title":"Image Pixelization with Differential Privacy","type":"project"},{"authors":["","Minwoo Lee"],"categories":["Few-Shot Learning"],"content":"","date":1596488329,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596488329,"objectID":"b37f64d0487d4da8ec7983bd492f0b51","permalink":"https://ArchitParnami.github.io/publication/01-fs-kws/","publishdate":"2020-08-03T16:58:49-04:00","relpermalink":"/publication/01-fs-kws/","section":"publication","summary":"Published in ACM 7th International Conference on Machine Learning Technologies (ICMLT), March 2022, Rome, Italy","tags":["Keyword Spotting","Speech Recognition","Audio"],"title":"Few-Shot Keyword Spotting With Prototypical Networks","type":"publication"},{"authors":["admin"],"categories":["Few-Shot-Learning"],"content":" Paper https://arxiv.org/abs/2006.15486 Code https://github.com/imtiazziko/LaplacianShot Main Idea Transfer Learning: Image embeddings are obtained by pre-training a network on the set of base classes using cross-entropy loss.\nTransductive Inference: Jointly classify all the query examples together.\nMethodology Given a labeled support set $\\mathbb{X_s} = \\bigcup_{c=1}^C$ with C test classes, where each novel class $c$ has $|\\mathbb{X_s^c}|$ labeled examples. Ex., $|\\mathbb{X_s^c}| = 1$ for one-shot learning. The object is then to classify unlabeled unseen query sample set $|\\mathbb{X_q}|$.\nLet $f_{\\theta}$ be the embedding function with parameters $\\theta$. Then:\n$$x_q = f_{\\theta}(z_q) \\in \\mathbb{R}^M,$$ where $x_q$ is the encoding of the data point $z_q$.\nFor each query point $x_q$, let there be a assignment vector $\\mathbf{y_q} = [y_{q,1}, \u0026hellip;, y_{q,C}]^t \\in {0,1}^C$\nso that binary $y_{q,c}$ is equal to 1 if $x_q$ belongs to class $c$. Then $\\mathbf{Y}$ denotes the $N \\times C$ matrix whose rows are formed by $\\mathbf{y}_q$, where $N$ is the number of query points in $\\mathbb{X_q}$. Then the objective to minimize at inference is given by (to find a $\\mathbf{Y}$ such that):\n$$\\mathcal{E}(\\mathbf{Y}) = \\mathcal{N}(\\mathbf{Y}) + \\frac{\\lambda}{2} \\mathcal{L}(\\mathbf{Y})$$\nwhere\n$$\\mathcal{N}(\\mathbf{Y}) = \\sum_{q=1}^N \\sum_{c=1}^C y_{q,c} d(x_q - \\mathbf{m}_c)$$\nand\n$$\\mathcal{L}(\\mathbf{Y}) = \\frac{1}{2} \\sum_{q,p} w(x_q, x_p) || \\mathbf{y}_q - \\mathbf{y}_p||^2$$\n$\\mathcal{N}(\\mathbf{Y})$ is minimized globally when each query point is assigned to the class of the nearest prototype $\\mathbf{m}_c$ from the support set using a distance metric $d(x_q, m_c)$. The Laplacian term (regularizer), $\\mathcal{L}(\\mathbf{Y})$, encourages nearby points $(x_p, x_q)$ in the label space to the same latent label assignment. $w$ is any similarity metric. $\\lambda$ is regularization parameter whose value is found by measuring performance on validation set. Using an iterative bound optimization procedure (Ex., Expectation-Maximization (EM)), $\\mathcal{E}(\\mathbf{Y})$ is minimized and $\\mathbf{Y}$ is found. Their optimization procedure converges within 15 iterations. Please refer to the paper for details on optimization method.\nResults Network dataset 1-shot 5-shot ResNet-18 miniImageNet $72.11 \\pm 0.19$ $82.31 \\pm 0.14$ ResNet-18 tieredImageNet $78.98 \\pm 0.21$ $86.39 \\pm 0.16$ ResNet-18 CUB $80.96$ $88.68$ ResNet-18 miniImageNet $\\rightarrow$ CUB1 $55.46$ $66.33$ Cite / BibTex @article{Ziko2020LaplacianRF, title={Laplacian Regularized Few-Shot Learning}, author={Imtiaz Masud Ziko and Jose Dolz and {\\'E}ric Granger and Ismail Ben Ayed}, journal={ArXiv}, year={2020}, volume={abs/2006.15486} } Cross Domain FSL: Training on miniImageNet and testing on CUB.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":1596487158,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596487158,"objectID":"13e598ed44a571f2753b3c78eb855bfb","permalink":"https://ArchitParnami.github.io/post/laplacian-fsl/","publishdate":"2020-08-03T16:39:18-04:00","relpermalink":"/post/laplacian-fsl/","section":"post","summary":" Paper https://arxiv.org/abs/2006.15486 Code https://github.com/imtiazziko/LaplacianShot Main Idea Transfer Learning: Image embeddings are obtained by pre-training a network on the set of base classes using cross-entropy loss.\nTransductive Inference: Jointly classify all the query examples together.\n","tags":["ICML","2020","Transductive","Transfer-Learning"],"title":"Laplacian Regularized Few-Shot Learning","type":"post"}]